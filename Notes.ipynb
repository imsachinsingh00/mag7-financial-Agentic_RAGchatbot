{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d05ccb93",
   "metadata": {
    "vscode": {
     "languageId": "bat"
    }
   },
   "source": [
    "\n",
    "## üìù **Summary and Project Scope**\n",
    "\n",
    "* **Target Companies:** MAG7 (AAPL, MSFT, AMZN, GOOGL, META, NVDA, TSLA)\n",
    "* **Target Filings:** 10-K and 10-Q\n",
    "* **Intended Years:** 2015‚Äì2025\n",
    "\n",
    "### **SEC Data Constraints**\n",
    "\n",
    "* Attempted to collect filings from 2015‚Äì2025, but after **2019-01-30**, the SEC migrated most filings to the **XBRL Viewer**, which delivers data primarily in XML/XBRL format (managed by U.S. government departments).\n",
    "* This notebook‚Äôs pipeline therefore processes filings from **2015 up to early 2019** (inclusive), with the HTML download and parsing approach.\n",
    "* The pipeline works fully for **AAPL, NVDA, and TSLA**. For the other MAG7 stocks, there were data access or metadata issues which limited HTML document availability.\n",
    "\n",
    "---\n",
    "\n",
    "## üí° **Tech Stack and Techniques Used**\n",
    "\n",
    "* **All tools used are free and open-source, with no paid dependencies.**\n",
    "* **LLMs:**\n",
    "\n",
    "  * **Groq Llama-3-70B-8192** (via free Groq API) is the **primary LLM** used for retrieval-augmented question answering (RAG).\n",
    "  * Also **experimented with OpenAI GPT-4.1-mini** (free/demo tier) to compare answer quality, especially in cases where the Groq Llama model was prone to hallucinations or less reliable responses.\n",
    "* **Embeddings:** Used HuggingFace‚Äôs `all-MiniLM-L6-v2` model for generating semantic vector embeddings.\n",
    "* **Vector Database:** Used FAISS (Facebook AI Similarity Search) for efficient vector storage and retrieval.\n",
    "* **Document Splitting:** Used LangChain‚Äôs `RecursiveCharacterTextSplitter` for smart, overlapping chunking of filing documents (preserving context across chunks).\n",
    "* **Metadata & Preprocessing:** Automatically parsed, cleaned, and attached rich metadata (company, filing type, fiscal period, accession, etc.) to each chunk.\n",
    "* **Agentic Tooling:** Built an agent that retrieves, grounds, and answers complex, multi-hop financial questions from filings using a fully open-source pipeline.\n",
    "* **Prompting and RAG:** Structured retrieval-augmented prompts with chunked context to LLMs for answer generation. (Note: ReAct-style reasoning and advanced chaining are also possible as a next step.)\n",
    "* **Cohere Embeddings:** Tried Cohere‚Äôs free embedding API, but the quota (approx. 500 calls per free user) was too limited for large-scale ingestion, so all main results are with HuggingFace embeddings.\n",
    "\n",
    "> **Note:** The primary LLM for Q\\&A is Groq Llama-3 (free tier), but I also tested OpenAI‚Äôs GPT-4.1-mini for higher answer reliability and to compare hallucination rates.\n",
    "> All code supports either backend with simple configuration changes.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31ddb4c5",
   "metadata": {},
   "source": [
    "# Imports & Configuration\n",
    "This cell sets up the environment for SEC filings processing and vector storage, loading dependencies, configuration, and API keys for downstream use.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4014818a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üî∑ Using Groq (Llama-3-70B-8192) for LLM Q&A\n"
     ]
    }
   ],
   "source": [
    "# === Imports & Configuration ===\n",
    "# Standard library imports\n",
    "import glob        # For finding files matching a pattern\n",
    "import json        # For handling JSON data\n",
    "import os          # For file and environment management\n",
    "\n",
    "# Third-party libraries\n",
    "from dotenv import load_dotenv         # Load environment variables from .env file\n",
    "from bs4 import BeautifulSoup          # HTML/XML parser for extracting text from filings\n",
    "\n",
    "# LangChain & Vector DB imports\n",
    "from langchain.docstore.document import Document    # Document wrapper for vector store\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter  # For smart text chunking\n",
    "from langchain.embeddings import CohereEmbeddings                  # Cohere embeddings integration but the api calls is limited (XXXXX)\n",
    "from langchain.vectorstores import FAISS                           # FAISS vector store\n",
    "from langchain.embeddings import HuggingFaceEmbeddings             # HuggingFace embeddings ( I ahve used all-MiniLM-L6-v2)\n",
    "import faiss                                                      # Facebook AI Similarity Search library (backend for FAISS)\n",
    "\n",
    "# Load environment variables (API keys, config) from .env file if present\n",
    "load_dotenv()\n",
    "\n",
    "# === Paths and API Keys ===\n",
    "METADATA_PATH = 'mag7_filing_metadata.json'   # JSON metadata for filings\n",
    "INPUT_DIR = 'filings'                         # Directory where SEC filings are stored (raw)\n",
    "OUTPUT_DIR = 'output'                         # Directory for processed outputs\n",
    "COHERE_API_KEY = os.getenv('COHERE_API_KEY')  # Cohere API key (for embeddings)\n",
    "COHERE_USER_AGENT = os.getenv('COHERE_USER_AGENT', 'langchain')  # User-Agent override if needed\n",
    "\n",
    "# Ensure the output directory exists (create if missing)\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "import os\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "def get_llm():\n",
    "    \"\"\"\n",
    "    Returns a Groq language model instance if GROQ_API_KEY is set.\n",
    "    Raises ValueError if not set.\n",
    "    \"\"\"\n",
    "    groq_api_key = os.getenv(\"GROQ_API_KEY\")\n",
    "    if groq_api_key:\n",
    "        print(\"üî∑ Using Groq (Llama-3-70B-8192) for LLM Q&A\")\n",
    "        return ChatGroq(model=\"llama3-70b-8192\", api_key=groq_api_key)\n",
    "    else:\n",
    "        raise ValueError(\n",
    "            \"‚ùå GROQ_API_KEY is not set. Please set it as an environment variable or pass with Docker using -e GROQ_API_KEY=your_key\"\n",
    "        )\n",
    "\n",
    "# Usage\n",
    "llm = get_llm()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b4b5ca0",
   "metadata": {},
   "source": [
    "# SEC MAG7 Filings Downloader and Cleaner (2015‚Äì2018)\n",
    "This notebook script downloads all 10-K and 10-Q filings (2015‚Äì2018) for the \"Magnificent 7\" companies from the SEC EDGAR database, saving the HTML files under `filings/{ticker}/`.  \n",
    "It also includes a function to clean and extract plain text from the HTML filings, ready for downstream chunking and embedding.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "388970b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CIKs: {'AAPL': '0000320193', 'MSFT': '0000789019', 'AMZN': '0001018724', 'GOOGL': '0001652044', 'META': '0001326801', 'NVDA': '0001045810', 'TSLA': '0001318605'}\n",
      "Fetching filings for AAPL...\n",
      "Fetching filings for MSFT...\n",
      "Fetching filings for AMZN...\n",
      "Fetching filings for GOOGL...\n",
      "Fetching filings for META...\n",
      "Fetching filings for NVDA...\n",
      "Fetching filings for TSLA...\n",
      "\n",
      "üì• Downloading filings for AAPL\n",
      "‚úÖ Saved filing to filings/AAPL\\0000320193-18-000145.html\n",
      "‚úÖ Saved filing to filings/AAPL\\0000320193-18-000100.html\n",
      "‚úÖ Saved filing to filings/AAPL\\0000320193-18-000070.html\n",
      "‚úÖ Saved filing to filings/AAPL\\0000320193-18-000007.html\n",
      "‚úÖ Saved filing to filings/AAPL\\0000320193-17-000070.html\n",
      "‚úÖ Saved filing to filings/AAPL\\0000320193-17-000009.html\n",
      "‚úÖ Saved filing to filings/AAPL\\0001628280-17-004790.html\n",
      "‚úÖ Saved filing to filings/AAPL\\0001628280-17-000717.html\n",
      "‚úÖ Saved filing to filings/AAPL\\0001628280-16-020309.html\n",
      "‚úÖ Saved filing to filings/AAPL\\0001628280-16-017809.html\n",
      "‚úÖ Saved filing to filings/AAPL\\0001193125-16-559625.html\n",
      "‚úÖ Saved filing to filings/AAPL\\0001193125-16-439878.html\n",
      "‚úÖ Saved filing to filings/AAPL\\0001193125-15-356351.html\n",
      "‚úÖ Saved filing to filings/AAPL\\0001193125-15-259935.html\n",
      "‚úÖ Saved filing to filings/AAPL\\0001193125-15-153166.html\n",
      "‚úÖ Saved filing to filings/AAPL\\0001193125-15-023697.html\n",
      "\n",
      "üì• Downloading filings for MSFT\n",
      "\n",
      "üì• Downloading filings for AMZN\n",
      "\n",
      "üì• Downloading filings for GOOGL\n",
      "\n",
      "üì• Downloading filings for META\n",
      "\n",
      "üì• Downloading filings for NVDA\n",
      "‚úÖ Saved filing to filings/NVDA\\0001045810-18-000150.html\n",
      "‚úÖ Saved filing to filings/NVDA\\0001045810-18-000114.html\n",
      "‚úÖ Saved filing to filings/NVDA\\0001045810-18-000080.html\n",
      "‚úÖ Saved filing to filings/NVDA\\0001045810-18-000010.html\n",
      "‚úÖ Saved filing to filings/NVDA\\0001045810-17-000172.html\n",
      "‚úÖ Saved filing to filings/NVDA\\0001045810-17-000123.html\n",
      "‚úÖ Saved filing to filings/NVDA\\0001045810-17-000075.html\n",
      "\n",
      "üì• Downloading filings for TSLA\n",
      "‚úÖ Saved filing to filings/TSLA\\0001564590-18-026353.html\n",
      "‚úÖ Saved filing to filings/TSLA\\0001564590-18-019254.html\n",
      "‚úÖ Saved filing to filings/TSLA\\0001564590-18-011086.html\n",
      "‚úÖ Saved filing to filings/TSLA\\0001564590-18-002956.html\n",
      "‚úÖ Saved filing to filings/TSLA\\0001564590-17-021343.html\n",
      "‚úÖ Saved filing to filings/TSLA\\0001564590-17-015705.html\n",
      "‚úÖ Saved filing to filings/TSLA\\0001564590-17-009968.html\n"
     ]
    }
   ],
   "source": [
    "import requests, os, time, json, re\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# --- Config ---\n",
    "USER_AGENT = \"im-----0@gmail.com\" # SEC requires a real email address here!\n",
    "MAG7_TICKERS = [\"AAPL\", \"MSFT\", \"AMZN\", \"GOOGL\", \"META\", \"NVDA\", \"TSLA\"]\n",
    "\n",
    "# === 1. Get CIKs for Each Ticker ===\n",
    "def get_cik_from_ticker(ticker: str) -> str:\n",
    "    \"\"\"\n",
    "    Get CIK (Central Index Key) for a ticker.\n",
    "    \"\"\"\n",
    "    url = \"https://www.sec.gov/files/company_tickers.json\"\n",
    "    headers = {\"User-Agent\": USER_AGENT}\n",
    "    response = requests.get(url, headers=headers)\n",
    "    data = response.json()\n",
    "    for entry in data.values():\n",
    "        if entry['ticker'].lower() == ticker.lower():\n",
    "            return str(entry['cik_str']).zfill(10)\n",
    "    return None\n",
    "\n",
    "mag7_ciks = {ticker: get_cik_from_ticker(ticker) for ticker in MAG7_TICKERS}\n",
    "print(\"CIKs:\", mag7_ciks)\n",
    "\n",
    "# === 2. Get Filings Metadata for Each CIK (2015‚Äì2018, 10-K and 10-Q) ===\n",
    "def get_filings_for_cik(cik, form_types=(\"10-K\", \"10-Q\"), start_year=2015, end_year=2018):\n",
    "    \"\"\"\n",
    "    Get filings for CIK, filter by form type and year range.\n",
    "    \"\"\"\n",
    "    url = f\"https://data.sec.gov/submissions/CIK{cik}.json\"\n",
    "    headers = {\"User-Agent\": USER_AGENT}\n",
    "    response = requests.get(url, headers=headers)\n",
    "    if response.status_code != 200:\n",
    "        print(f\"Failed to fetch for CIK {cik}\")\n",
    "        return []\n",
    "    data = response.json()\n",
    "    recent = data.get(\"filings\", {}).get(\"recent\", {})\n",
    "    results = []\n",
    "    for i in range(len(recent.get(\"form\", []))):\n",
    "        form = recent[\"form\"][i]\n",
    "        if form not in form_types: continue\n",
    "        date = recent[\"filingDate\"][i]\n",
    "        year = int(date.split(\"-\")[0])\n",
    "        if year < start_year or year > end_year: continue\n",
    "        accession_raw = recent[\"accessionNumber\"][i]\n",
    "        results.append({\n",
    "            \"form\": form, \"date\": date, \"year\": year,\n",
    "            \"accession\": accession_raw.replace(\"-\", \"\"),\n",
    "            \"accession_raw\": accession_raw\n",
    "        })\n",
    "    return results\n",
    "\n",
    "# --- Get all filings metadata for the MAG7 in 2015‚Äì2018 ---\n",
    "mag7_filings = {}\n",
    "for ticker, cik in mag7_ciks.items():\n",
    "    print(f\"Fetching filings for {ticker}...\")\n",
    "    mag7_filings[ticker] = get_filings_for_cik(cik, start_year=2015, end_year=2018)\n",
    "    time.sleep(0.5)  # Be nice to SEC!\n",
    "\n",
    "# --- Save metadata for reference ---\n",
    "with open(\"mag7_filing_metadata.json\", \"w\") as f:\n",
    "    json.dump(mag7_filings, f, indent=2)\n",
    "\n",
    "# === 3. Download HTML Filings ===\n",
    "def download_filing_html(cik, accession_raw, save_dir, user_agent=USER_AGENT):\n",
    "    \"\"\"\n",
    "    Download main HTML filing if present.\n",
    "    \"\"\"\n",
    "    cik_clean = str(int(cik))\n",
    "    accession_nodash = accession_raw.replace(\"-\", \"\")\n",
    "    base_url = f\"https://www.sec.gov/Archives/edgar/data/{cik_clean}/{accession_nodash}/\"\n",
    "    index_url = base_url + accession_raw + \"-index.html\"\n",
    "    headers = {\"User-Agent\": user_agent}\n",
    "    resp = requests.get(index_url, headers=headers)\n",
    "    if resp.status_code != 200:\n",
    "        print(f\"‚ùå Failed to load index page for {accession_raw}\")\n",
    "        return None\n",
    "    soup = BeautifulSoup(resp.text, \"html.parser\")\n",
    "    table = soup.find(\"table\", class_=\"tableFile\", summary=\"Document Format Files\")\n",
    "    if table is None:\n",
    "        print(f\"‚ö†Ô∏è No document table found for {accession_raw}\")\n",
    "        return None\n",
    "    main_doc_link = None\n",
    "    for link in table.find_all(\"a\"):\n",
    "        href = link.get(\"href\", \"\")\n",
    "        if href.endswith(\".htm\") or href.endswith(\".txt\"):\n",
    "            main_doc_link = href\n",
    "            break\n",
    "    if not main_doc_link:\n",
    "        print(f\"‚ö†Ô∏è No main document found in index for {accession_raw}\")\n",
    "        return None\n",
    "    full_doc_url = \"https://www.sec.gov\" + main_doc_link\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    file_path = os.path.join(save_dir, f\"{accession_raw}.html\")\n",
    "    doc_resp = requests.get(full_doc_url, headers=headers)\n",
    "    with open(file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(doc_resp.text)\n",
    "    print(f\"‚úÖ Saved filing to {file_path}\")\n",
    "    return file_path\n",
    "\n",
    "# --- Download filings (HTML only) for all tickers ---\n",
    "for ticker in mag7_ciks:\n",
    "    print(f\"\\nüì• Downloading filings for {ticker}\")\n",
    "    filings = mag7_filings[ticker]\n",
    "    for filing in filings:\n",
    "        download_filing_html(\n",
    "            cik=mag7_ciks[ticker],\n",
    "            accession_raw=filing[\"accession_raw\"],\n",
    "            save_dir=f\"filings/{ticker}\"\n",
    "        )\n",
    "        time.sleep(0.5)\n",
    "\n",
    "# --- Clean HTML to Extract Text ---\n",
    "def clean_filing_text(html_path):\n",
    "    with open(html_path, 'r', encoding='utf-8') as file:\n",
    "        soup = BeautifulSoup(file, \"html.parser\")\n",
    "    for tag in soup([\"script\", \"style\", \"table\", \"noscript\"]):\n",
    "        tag.decompose()\n",
    "    raw_text = soup.get_text(separator=\"\\n\")\n",
    "    lines = [line.strip() for line in raw_text.splitlines()]\n",
    "    clean_lines = [line for line in lines if line]\n",
    "    text = \"\\n\".join(clean_lines)\n",
    "    text = re.sub(r'\\n[A-Z\\s]{10,}\\n', '\\n', text)  # Remove most all-caps lines (tables)\n",
    "    return text\n",
    "\n",
    "\n",
    "##----- You can use the json format also to converta nd it saves the files to processed folder in the same directory--------##\n",
    "\n",
    "# def process_and_save_filing(ticker, cik, filing, raw_dir=\"filings\", out_dir=\"processed\"):\n",
    "#     in_path = os.path.join(raw_dir, ticker, f\"{filing['accession_raw']}.html\")\n",
    "#     if not os.path.exists(in_path):\n",
    "#         print(f\"Missing: {in_path}\")\n",
    "#         return\n",
    "#     try:\n",
    "#         content = clean_filing_text(in_path)\n",
    "#         output = {\n",
    "#             \"ticker\": ticker,\n",
    "#             \"cik\": cik,\n",
    "#             \"form\": filing[\"form\"],\n",
    "#             \"date\": filing[\"date\"],\n",
    "#             \"accession\": filing[\"accession_raw\"],\n",
    "#             \"text\": content\n",
    "#         }\n",
    "#         os.makedirs(out_dir, exist_ok=True)\n",
    "#         out_path = os.path.join(out_dir, f\"{ticker}_{filing['accession_raw']}.json\")\n",
    "#         with open(out_path, \"w\", encoding=\"utf-8\") as f:\n",
    "#             json.dump(output, f, indent=2)\n",
    "#         print(f\"‚úÖ Saved: {out_path}\")\n",
    "#     except Exception as e:\n",
    "#         print(f\"‚ùå Error processing {in_path}: {e}\")\n",
    "\n",
    "# for ticker, filings in mag7_filings.items():\n",
    "#     cik = mag7_ciks[ticker]\n",
    "#     print(f\"\\nüßº Processing filings for {ticker}...\")\n",
    "#     for filing in filings:\n",
    "#         process_and_save_filing(ticker, cik, filing)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8da4a23c",
   "metadata": {},
   "source": [
    "# Load Filing Metadata & Extract Raw Filing Text\n",
    "This section loads the SEC filings' metadata and extracts clean text from each raw HTML filing, attaching relevant metadata (company, accession, form, year, date, etc.) to each document.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4007e41c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 30 documents.\n"
     ]
    }
   ],
   "source": [
    "# === Load Filing Metadata & Raw Text ===\n",
    "\n",
    "# Load filing metadata from the provided JSON file.\n",
    "with open(METADATA_PATH, 'r', encoding='utf-8') as f:\n",
    "    filing_metadata = json.load(f)\n",
    "\n",
    "def load_filings_text(input_dir: str) -> list[Document]:\n",
    "    \"\"\"\n",
    "    Loads SEC filing HTML files, extracts clean text, and attaches metadata.\n",
    "\n",
    "    Args:\n",
    "        input_dir (str): Path to directory containing HTML filings.\n",
    "\n",
    "    Returns:\n",
    "        list[Document]: List of LangChain Document objects with text and metadata.\n",
    "    \"\"\"\n",
    "    docs = []\n",
    "    # Recursively find all .html filing files\n",
    "    for path in glob.glob(f\"{input_dir}/**/*.html\", recursive=True):\n",
    "        company = os.path.basename(os.path.dirname(path))\n",
    "        accession_raw = os.path.splitext(os.path.basename(path))[0]\n",
    "        # Read HTML content\n",
    "        with open(path, 'r', encoding='utf-8') as hf:\n",
    "            html = hf.read()\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        # Remove unwanted elements\n",
    "        for tag in soup(['script', 'style']):\n",
    "            tag.decompose()\n",
    "        # Extract visible text\n",
    "        text = soup.get_text(separator=' ')\n",
    "        # Assemble metadata\n",
    "        meta = {\n",
    "            'source': path,\n",
    "            'company': company,\n",
    "            'accession_raw': accession_raw\n",
    "        }\n",
    "        # Match and add extra metadata from filing_metadata\n",
    "        entries = filing_metadata.get(company, [])\n",
    "        match = next((e for e in entries if e['accession_raw'] == accession_raw), None)\n",
    "        if match:\n",
    "            meta.update({\n",
    "                'form': match['form'],\n",
    "                'date': match['date'],\n",
    "                'year': match['year']\n",
    "            })\n",
    "        else:\n",
    "            print(f\"‚ö†Ô∏è No metadata for {company} {accession_raw}\")\n",
    "        # Create LangChain Document with text and metadata\n",
    "        docs.append(Document(page_content=text, metadata=meta))\n",
    "    return docs\n",
    "\n",
    "# Load all filings as Document objects with attached metadata\n",
    "documents = load_filings_text(INPUT_DIR)\n",
    "print(f\"Loaded {len(documents)} documents.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e1a30e",
   "metadata": {},
   "source": [
    "# Chunking Documents & Saving to JSONL\n",
    "Now we split each filing into overlapping text chunks (for better retrieval) and save the resulting chunks‚Äîwith metadata‚Äîto a `.jsonl` file for easy reuse.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f77f0bbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 9303 chunks.\n",
      "Saved chunks to output\\mag7_chunks_2015_2018.jsonl\n"
     ]
    }
   ],
   "source": [
    "# === Chunking Documents ===\n",
    "\n",
    "# Initialize LangChain's RecursiveCharacterTextSplitter for smart, overlapping chunks\n",
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,         # Max tokens/characters per chunk\n",
    "    chunk_overlap=200,       # Overlap for context continuity\n",
    "    separators=[\"\\n\\n\", \"\\n\", \" \"]  # Prioritize splitting at paragraph or line breaks\n",
    ")\n",
    "\n",
    "# Split all documents into chunks\n",
    "chunks = splitter.split_documents(documents)\n",
    "print(f\"Generated {len(chunks)} chunks.\")\n",
    "\n",
    "# === Cell 4: Save Chunks to JSONL ===\n",
    "\n",
    "# Save all chunks as JSONL (one JSON object per line, easy for downstream processing)\n",
    "jsonl_path = os.path.join(OUTPUT_DIR, 'mag7_chunks_2015_2018.jsonl')\n",
    "with open(jsonl_path, 'w', encoding='utf-8') as out_f:\n",
    "    for chunk in chunks:\n",
    "        # Each chunk gets its text and metadata combined into a record\n",
    "        record = {'text': chunk.page_content, **chunk.metadata}\n",
    "        out_f.write(json.dumps(record) + '\\n')\n",
    "print(f\"Saved chunks to {jsonl_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d39872",
   "metadata": {},
   "source": [
    "# Build FAISS Vector Store with Embeddings\n",
    "This section converts all text chunks into embeddings (using HuggingFace's MiniLM model) and saves them into a FAISS vector store for fast semantic search.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "97051ba3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ FAISS index built and saved to 'output\\faiss_mag7'\n"
     ]
    }
   ],
   "source": [
    "# === Build FAISS Vector Store ===\n",
    "\n",
    "# Choose embedding provider: uncomment ONE at a time, or loop through all  ( add the api key in .env and use you own embedding model)\n",
    "\n",
    "## --- HuggingFace (local, no API key needed) ---\n",
    "# Initialize the embedding model (MiniLM is fast , free & good for small data)\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# Create FAISS vector store directly from all document chunks\n",
    "vector_store = FAISS.from_documents(chunks, embeddings)\n",
    "\n",
    "\n",
    "# Save FAISS index and associated data for downstream retrieval use\n",
    "faiss_output_dir = os.path.join(OUTPUT_DIR, 'faiss_mag7')\n",
    "vector_store.save_local(faiss_output_dir)\n",
    "print(f\"‚úÖ FAISS index built and saved to '{faiss_output_dir}'\")\n",
    "\n",
    "## --- OpenAI (requires OPENAI_API_KEY) ---\n",
    "# openai_embeddings = OpenAIEmbeddings(\n",
    "#     model=\"text-embedding-ada-002\",         # Or other supported models\n",
    "#     openai_api_key=os.getenv('OPENAI_API_KEY')\n",
    "# )\n",
    "# openai_vector_store = FAISS.from_documents(chunks, openai_embeddings)\n",
    "# openai_vector_store.save_local(os.path.join(OUTPUT_DIR, 'faiss_mag7_openai'))\n",
    "# print(\"‚úÖ FAISS index (OpenAI) saved to 'output/faiss_mag7_openai'\")\n",
    "\n",
    "## --- Cohere (requires COHERE_API_KEY) ---\n",
    "# cohere_embeddings = CohereEmbeddings(\n",
    "#     model=\"embed-english-v3.0\",  # Or whichever Cohere model you want\n",
    "#     cohere_api_key=COHERE_API_KEY\n",
    "# )\n",
    "# cohere_vector_store = FAISS.from_documents(chunks, cohere_embeddings)\n",
    "# cohere_vector_store.save_local(os.path.join(OUTPUT_DIR, 'faiss_mag7_cohere'))\n",
    "# print(\"‚úÖ FAISS index (Cohere) saved to 'output/faiss_mag7_cohere'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f5f4fa2",
   "metadata": {},
   "source": [
    "# Query the FAISS Vector Store (HuggingFace Embeddings)\n",
    "This cell demonstrates how to load your FAISS vector store and retrieve the top relevant chunks for a given question using semantic search.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d061fd71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Hit 1 ---\n",
      "Company: AAPL\n",
      "Form: 10-K\n",
      "Date: 2017-11-03\n",
      "Snippet: total size of the program from $200 billion to $250 billion through March 2018. This included increasing its share repurchase authorization from $140 billion to $175 billion and raising its quarterly dividend from $0.52 to $0.57 per share beginning in May 2016. During 2016, the Company spent $29.0 billion to repurchase shares of its common stock and paid dividends and dividend equivalents of $12.2 billion. Additionally, the Company issued $23.9 billion of U.S. dollar-denominated term debt and A$ ...\n",
      "\n",
      "--- Hit 2 ---\n",
      "Company: AAPL\n",
      "Form: 10-K\n",
      "Date: 2015-10-28\n",
      "Snippet: $ \n",
      " 183 \n",
      " ¬†¬† \n",
      " ¬†¬† \n",
      " $ \n",
      " 183 \n",
      " ¬†¬† \n",
      " \n",
      " ¬†   Apple Inc. | 2015 Form 10-K | 21\n",
      " \n",
      " \n",
      " \n",
      " Table of Contents \n",
      " \n",
      " \n",
      " Item¬†6. \n",
      " Selected Financial Data    The information set forth below for the five years ended\n",
      "September¬†26, 2015, is not necessarily indicative of results of future operations, and should be read in conjunction with Part II, Item¬†7, ‚ÄúManagement‚Äôs Discussion and Analysis of Financial Condition and Results of\n",
      "Operations‚Äù and the consolidated financial statements and related notes thereto includ ...\n",
      "\n",
      "--- Hit 3 ---\n",
      "Company: AAPL\n",
      "Form: 10-K\n",
      "Date: 2015-10-28\n",
      "Snippet: Apple Inc. | 2015 Form 10-K | 19\n",
      " \n",
      " \n",
      " \n",
      " Table of Contents \n",
      " Purchases of Equity Securities by the Issuer and Affiliated Purchasers  \n",
      " Share repurchase activity during the three months ended September¬†26, 2015 was as follows (in millions, except number of shares, which are reflected\n",
      "in thousands, and per share amounts):    ¬† \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "   Periods \n",
      " ¬†¬† \n",
      " Total¬†Number of Shares Purchased \n",
      " ¬† \n",
      " ¬† \n",
      " Average Price ¬†¬†¬†¬†Paid¬†Per¬†¬†¬†¬† Share \n",
      " ¬† \n",
      " ¬† \n",
      " Total¬†Number of Shares Pu ...\n",
      "\n",
      "--- Hit 4 ---\n",
      "Company: AAPL\n",
      "Form: 10-K\n",
      "Date: 2018-11-05\n",
      "Snippet: and shareholders‚Äô equity $ 365,725 $ 375,319 See accompanying Notes to Consolidated Financial Statements. Apple Inc. | 2018 Form 10-K |  40 Apple Inc. CONSOLIDATED STATEMENTS OF SHAREHOLDERS‚Äô EQUITY (In¬†millions, except number of shares which are reflected in thousands and per share amounts) ¬† Common Stock and Additional Paid-In Capital ¬† Retained Earnings ¬† Accumulated Other Comprehensive Income/(Loss) ¬† Total Shareholders‚Äô Equity ¬† Shares ¬† Amount ¬† Balances as of September 26, 2015 5,578,753  ...\n",
      "\n",
      "--- Hit 5 ---\n",
      "Company: AAPL\n",
      "Form: 10-Q\n",
      "Date: 2018-05-02\n",
      "Snippet: million  and  $1.0 billion  of interest expense on its term debt for  the three- and six-month periods ended April 1, 2017 , respectively. Apple Inc. | Q2 2018 Form 10-Q |  14 As of  March¬†31, 2018  and  September¬†30, 2017 , the fair value of the Company‚Äôs Notes, based on Level 2 inputs, was  $111.1 billion  and  $106.1 billion , respectively. Note 6 ‚Äì Shareholders‚Äô Equity Share Repurchase Program As of  March¬†31, 2018 , the Company had an authorized share repurchase program of up to  $210 billi ...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "# Re-initialize the embeddings (must match the model used during indexing)\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name='all-MiniLM-L6-v2'\n",
    ")\n",
    "\n",
    "# Load the FAISS index from disk (use allow_dangerous_deserialization=True in Colab)\n",
    "vector_store = FAISS.load_local(\n",
    "    os.path.join(OUTPUT_DIR, 'faiss_mag7'),\n",
    "    embeddings,\n",
    "    allow_dangerous_deserialization=True\n",
    ")\n",
    "\n",
    "# Define your sample query\n",
    "query = \"What was Apple's return on equity in their 2018 10-K?\"\n",
    "\n",
    "# Perform similarity search to get top 5 most relevant chunks\n",
    "hits = vector_store.similarity_search(query, k=5)\n",
    "\n",
    "# Display results with metadata and snippet preview\n",
    "for idx, hit in enumerate(hits, start=1):\n",
    "    print(f\"--- Hit {idx} ---\")\n",
    "    print(\"Company:\", hit.metadata.get('company'))\n",
    "    print(\"Form:\", hit.metadata.get('form'))\n",
    "    print(\"Date:\", hit.metadata.get('date'))\n",
    "    print(\"Snippet:\", hit.page_content[:500], \"...\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "567d024e",
   "metadata": {},
   "source": [
    "# Hybrid Search Pipeline: BM25 Keyword Retrieval + Semantic Embedding Re-Ranking\n",
    "This cell demonstrates a hybrid retrieval approach:  \n",
    "1. **BM25** is used for fast keyword-based candidate selection.  \n",
    "2. **Embeddings** are then used to re-rank these candidates by semantic similarity to the query.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e04ec503",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 Hybrid BM25+Embedding Results:\n",
      "{'company': 'NVDA', 'form': '10-Q', 'date': Timestamp('2017-08-23 00:00:00')} | Score: 0.5750\n",
      "Snippet: year  2018  was $688 million, up 117% from a year earlier and up 24% sequentially. Net income and net income per diluted share for the  second quarter of fiscal  year  2018  were $583 million and $0.9...\n",
      "\n",
      "{'company': 'NVDA', 'form': '10-Q', 'date': Timestamp('2017-11-21 00:00:00')} | Score: 0.5187\n",
      "Snippet: and improved gross and operating margins.  During the  first nine months of fiscal  year  2018 , we returned to shareholders $909 million in share repurchases and $250 million in cash dividends. For f...\n",
      "\n",
      "{'company': 'AAPL', 'form': '10-Q', 'date': Timestamp('2018-08-01 00:00:00')} | Score: 0.4260\n",
      "Snippet: the lower 2018 blended U.S. tax rate as a result of the Act and the reduction in its provisional tax expense estimate, partially offset by higher taxes on foreign earnings during the third quarter of ...\n",
      "\n",
      "{'company': 'NVDA', 'form': '10-K', 'date': Timestamp('2018-02-28 00:00:00')} | Score: 0.4171\n",
      "Snippet: us upon this exercise of our option. Refer to Note 11 of the Notes to the Consolidated Financial Statements in Part IV, Item 15 of this Annual Report on Form 10-K for further discussion regarding the ...\n",
      "\n",
      "{'company': 'NVDA', 'form': '10-K', 'date': Timestamp('2018-02-28 00:00:00')} | Score: 0.3731\n",
      "Snippet: plans. Stock Performance Graphs¬† The following graph compares the cumulative total shareholder return for our common stock, the S&P 500 Index, and the NASDAQ 100 Index for the five years ended  Januar...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from rank_bm25 import BM25Okapi\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Load the chunks into DataFrame\n",
    "df = pd.read_json(jsonl_path, lines=True)\n",
    "\n",
    "# --- BM25 Keyword Search ---\n",
    "# Tokenize each document for BM25 scoring\n",
    "tokenized_texts = [text.split() for text in df['text']]\n",
    "bm25 = BM25Okapi(tokenized_texts)\n",
    "\n",
    "# Tokenize the query\n",
    "tokenized_query = query.split()\n",
    "\n",
    "# Compute BM25 scores for all chunks\n",
    "bm25_scores = bm25.get_scores(tokenized_query)\n",
    "\n",
    "# Get indices of the top-N BM25 candidates (high to low)\n",
    "top_n = 10\n",
    "bm25_indices = np.argsort(bm25_scores)[::-1][:top_n]\n",
    "\n",
    "# --- Semantic Re-ranking using Embeddings ---\n",
    "# Generate embedding for the query\n",
    "query_emb = embeddings.embed_documents([query])[0]\n",
    "\n",
    "candidates = []\n",
    "for i in bm25_indices:\n",
    "    # Generate embedding for each candidate document\n",
    "    doc_emb = embeddings.embed_documents([df.loc[i, 'text']])[0]\n",
    "    # Compute cosine similarity between query and document\n",
    "    cosine_similarity = np.dot(query_emb, doc_emb) / (np.linalg.norm(query_emb) * np.linalg.norm(doc_emb))\n",
    "    candidates.append((i, cosine_similarity))\n",
    "\n",
    "# Sort candidates by highest cosine similarity\n",
    "candidates.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# --- Display the Top Results ---\n",
    "print(\"Top 5 Hybrid BM25+Embedding Results:\")\n",
    "for idx, score in candidates[:5]:\n",
    "    meta = df.loc[idx, ['company', 'form', 'date']].to_dict()\n",
    "    snippet = df.loc[idx, 'text'][:200].replace('\\n', ' ')\n",
    "    print(f\"{meta} | Score: {score:.4f}\\nSnippet: {snippet}...\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ca10fca",
   "metadata": {},
   "source": [
    "#  RAG: Generate Answers with LLM Using Retrieved Context\n",
    "This cell demonstrates a typical RAG (Retrieval-Augmented Generation) workflow:  \n",
    "1. Retrieve relevant context chunks using FAISS vector search.  \n",
    "2. Construct a prompt with the context and the user query.  \n",
    "3. Use a language model (e.g., GPT-4) to generate a grounded answer.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31996ad0",
   "metadata": {},
   "source": [
    "## ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2b96b5c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: The excerpts provided do not explicitly state Apple's revenue for Q1 2018. However, there are some relevant financial figures and notes related to services revenue and general expenses, but no direct total revenue number for Q1 2018 is mentioned.\n",
      "\n",
      "To accurately answer your question:\n",
      "\n",
      "- The Q1 2018 Form 10-Q is referenced, but the exact revenue figure for Q1 2018 is not included in the text.\n",
      "- The excerpts mention details about services revenue, one-time items, and expenses but no consolidated revenue total.\n",
      "\n",
      "**Conclusion:**  \n",
      "Based on the provided excerpts, Apple‚Äôs total revenue for Q1 2018 is not specifically stated, so I cannot provide the exact revenue number for that quarter from the given information.\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import LLMChain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "# Define the model\n",
    "model = ChatOpenAI(model=\"gpt-4.1-mini\")  # Use the appropriate model\n",
    "# model = get_llm()\n",
    "\n",
    "# Define the prompt template to structure the query and context\n",
    "prompt_template = \"\"\"\n",
    "Here are some excerpts from financial documents related to your query:\n",
    "\n",
    "{context}\n",
    "\n",
    "Based on the above context, please answer the following question:\n",
    "{query}\n",
    "\"\"\"\n",
    "\n",
    "# Initialize LLMChain with the model and the prompt template\n",
    "prompt = PromptTemplate(input_variables=[\"query\", \"context\"], template=prompt_template)\n",
    "llm_chain = LLMChain(llm=model, prompt=prompt)\n",
    "\n",
    "# Function to generate an answer from the query and the retrieved context\n",
    "def get_answer(query):\n",
    "    # Perform similarity search to retrieve relevant document chunks\n",
    "    hits = vector_store.similarity_search(query, k=5)\n",
    "    \n",
    "    # Prepare the context by concatenating snippets from the top k documents\n",
    "    context = \"\\n\".join([hit.page_content[:500] for hit in hits])  # You can adjust the snippet length as needed\n",
    "    \n",
    "    # Get the answer from the model using LLMChain\n",
    "    answer = llm_chain.run({\"query\": query, \"context\": context})\n",
    "    return answer\n",
    "\n",
    "# Example quer?y\n",
    "query = \"What was Apple's revenue for Q1 2018?\"\n",
    "answer = get_answer(query)\n",
    "\n",
    "print(\"Answer:\", answer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea84785e",
   "metadata": {},
   "source": [
    "## Groq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d70aca6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üî∑ Using Groq (Llama-3-70B-8192) for LLM Q&A\n",
      "Answer: Based on the provided excerpts, Apple's revenue for Q1 2018 is not explicitly stated. However, the revenue for Q2 2018 and Q3 2017 are mentioned, but not Q1 2018.\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import LLMChain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "# Define the model\n",
    "# model = ChatOpenAI(model=\"gpt-4.1-mini\")  # Use the appropriate model\n",
    "model = get_llm()\n",
    "\n",
    "# Define the prompt template to structure the query and context\n",
    "prompt_template = \"\"\"\n",
    "Here are some excerpts from financial documents related to your query:\n",
    "\n",
    "{context}\n",
    "\n",
    "Based on the above context, please answer the following question:\n",
    "{query}\n",
    "\"\"\"\n",
    "\n",
    "# Initialize LLMChain with the model and the prompt template\n",
    "prompt = PromptTemplate(input_variables=[\"query\", \"context\"], template=prompt_template)\n",
    "llm_chain = LLMChain(llm=model, prompt=prompt)\n",
    "\n",
    "# Function to generate an answer from the query and the retrieved context\n",
    "def get_answer(query):\n",
    "    # Perform similarity search to retrieve relevant document chunks\n",
    "    hits = vector_store.similarity_search(query, k=5)\n",
    "    \n",
    "    # Prepare the context by concatenating snippets from the top k documents\n",
    "    context = \"\\n\".join([hit.page_content[:500] for hit in hits])  # You can adjust the snippet length as needed\n",
    "    \n",
    "    # Get the answer from the model using LLMChain\n",
    "    answer = llm_chain.run({\"query\": query, \"context\": context})\n",
    "    return answer\n",
    "\n",
    "# Example quer?y\n",
    "query = \"What was Apple's revenue for Q1 2018?\"\n",
    "answer = get_answer(query)\n",
    "\n",
    "print(\"Answer:\", answer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e2e1b38",
   "metadata": {},
   "source": [
    "## ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9459da45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: The excerpts provided do not explicitly state Apple's total revenue for Q1 2018. They mention certain details about services net sales, one-time items, and some expenses, but the total revenue figure for Q1 2018 is not included in the text.\n",
      "\n",
      "If you need the exact revenue for Q1 2018, it would typically be found in the full Apple Q1 2018 Form 10-Q or Form 10-K filing. Based on publicly available information, Apple's reported total revenue for Q1 2018 was approximately **$88.3 billion**. However, this figure is not present in the excerpts you provided.\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import LLMChain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "# Define the model\n",
    "model = ChatOpenAI(model=\"gpt-4.1-mini\")  # Use the appropriate model\n",
    "# model = get_llm()\n",
    "\n",
    "# Define the prompt template to structure the query and context\n",
    "prompt_template = \"\"\"\n",
    "Here are some excerpts from financial documents related to your query:\n",
    "\n",
    "{context}\n",
    "\n",
    "Based on the above context, please answer the following question:\n",
    "{query}\n",
    "\"\"\"\n",
    "\n",
    "# Initialize LLMChain with the model and the prompt template\n",
    "prompt = PromptTemplate(input_variables=[\"query\", \"context\"], template=prompt_template)\n",
    "llm_chain = LLMChain(llm=model, prompt=prompt)\n",
    "\n",
    "# Function to generate an answer from the query and the retrieved context\n",
    "def get_answer(query):\n",
    "    # Perform similarity search to retrieve relevant document chunks\n",
    "    hits = vector_store.similarity_search(query, k=5)\n",
    "    \n",
    "    # Prepare the context by concatenating snippets from the top k documents\n",
    "    context = \"\\n\".join([hit.page_content[:500] for hit in hits])  # You can adjust the snippet length as needed\n",
    "    \n",
    "    # Get the answer from the model using LLMChain\n",
    "    answer = llm_chain.run({\"query\": query, \"context\": context})\n",
    "    return answer\n",
    "\n",
    "# Example quer?y\n",
    "query = \"What was Apple's revenue for Q1 2018?\"\n",
    "answer = get_answer(query)\n",
    "\n",
    "print(\"Answer:\", answer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c22e57",
   "metadata": {},
   "source": [
    "\n",
    "### Conversational Q&A Agent for SEC Filings (Manual JSON Parsing)\n",
    "### ---------------------------------------------------------------\n",
    "### This code defines a function to answer financial queries\n",
    "### using a vectorstore (FAISS), an LLM, and maintains chat history.\n",
    "### Returns answers in JSON format with context citations.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d933582",
   "metadata": {},
   "source": [
    "## Groq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2e553f27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "System: content='{\\n  \"answer\": \"Hello! How can I assist you with your financial analysis today?\",\\n  \"sources\": [],\\n  \"confidence\": 1.0\\n}' additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 34, 'prompt_tokens': 125, 'total_tokens': 159, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-mini', 'system_fingerprint': 'fp_6f2eabb9a5', 'finish_reason': 'stop', 'logprobs': None} id='run--534ed81e-f597-4d09-b65a-296f29ba1179-0'\n",
      "Sources: [{'company': 'TSLA', 'filing': '10-Q', 'period': '2018-11-02', 'snippet': '18', 'url': 'filings\\\\TSLA\\\\0001564590-18-026353.html'}, {'company': 'TSLA', 'filing': '10-Q', 'period': '2018-08-06', 'snippet': '22', 'url': 'filings\\\\TSLA\\\\0001564590-18-019254.html'}, {'company': 'TSLA', 'filing': '10-Q', 'period': '2017-05-10', 'snippet': '41', 'url': 'filings\\\\TSLA\\\\0001564590-17-009968.html'}, {'company': 'TSLA', 'filing': '10-Q', 'period': '2017-08-04', 'snippet': '20', 'url': 'filings\\\\TSLA\\\\0001564590-17-015705.html'}, {'company': 'TSLA', 'filing': '10-Q', 'period': '2018-08-06', 'snippet': '17', 'url': 'filings\\\\TSLA\\\\0001564590-18-019254.html'}]\n",
      "Confidence: 0.85 \n",
      "\n",
      "\n",
      "System: content='{\\n  \"answer\": \"Apple\\'s revenue in Q1 2018 was approximately $88.3 billion.\",\\n  \"sources\": [\\n    {\\n      \"company\": \"Apple Inc.\",\\n      \"filing\": \"Q1 2018 Form 10-Q\",\\n      \"period\": \"Q1 2018\",\\n      \"snippet\": \"Apple\\'s Q1 2018 revenue was reported as approximately $88.3 billion in the Q1 2018 Form 10-Q.\",\\n      \"url\": \"https://www.sec.gov/Archives/edgar/data/320193/000032019318000070/a10-q20180331.htm\"\\n    }\\n  ],\\n  \"confidence\": 0.95\\n}' additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 147, 'prompt_tokens': 902, 'total_tokens': 1049, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-mini', 'system_fingerprint': 'fp_6f2eabb9a5', 'finish_reason': 'stop', 'logprobs': None} id='run--e9394094-2a44-46ce-8c7e-813f6fffdb92-0'\n",
      "Sources: [{'company': 'AAPL', 'filing': '10-Q', 'period': '2018-05-02', 'snippet': 'to its future growth and competitive position in the marketplace, and to the development of new and updated products and services that are central to the Company‚Äôs core business strategy. Selling, General and Administrative The growth in selling, general and administrative expense during the second quarter and first six months of 2018 compared to the same periods in 2017 was driven primarily by increases in headcount-related expenses and infrastructure-related costs. Apple Inc. | Q2 2018 Form 10', 'url': 'filings\\\\AAPL\\\\0000320193-18-000070.html'}, {'company': 'AAPL', 'filing': '10-Q', 'period': '2018-02-02', 'snippet': 'period presented or retrospectively with the cumulative effect recognized as of the date of adoption. The Company will adopt the new revenue standards in its first quarter of 2019 utilizing the full retrospective transition method. The new revenue standards are not expected to have a material impact on the amount and timing of revenue recognized in the Company‚Äôs consolidated financial statements. Apple Inc. | Q1 2018 Form 10-Q |  28 Liquidity and Capital Resources The following tables present se', 'url': 'filings\\\\AAPL\\\\0000320193-18-000007.html'}, {'company': 'AAPL', 'filing': '10-Q', 'period': '2018-08-01', 'snippet': 'and paid dividends and dividend equivalents of  $3.7 billion  during the  third  quarter of  2018 . Apple Inc. | Q3 2018 Form 10-Q |  23 Sales Data The following table shows net sales by reportable segment and net sales and unit sales by product for  the three- and nine-month periods ended June 30, 2018  and  July\\xa01, 2017  (dollars in millions and units in thousands): \\xa0 Three Months Ended \\xa0 Nine Months Ended \\xa0 June\\xa030,  2018 \\xa0 July\\xa01,  2017 \\xa0 Change \\xa0 June\\xa030,  2018 \\xa0 July\\xa01,  2017 \\xa0 Change Net ', 'url': 'filings\\\\AAPL\\\\0000320193-18-000100.html'}, {'company': 'AAPL', 'filing': '10-K', 'period': '2018-11-05', 'snippet': '229,234 $ 215,639 \\xa0 (1) Includes deferrals and amortization of related software upgrade rights and non-software services. (2) Includes revenue from Digital Content and Services, AppleCare, Apple Pay, licensing and other services. Services net sales in 2018 included a favorable one-time item of  $236 million  in connection with the final resolution of various lawsuits. Services net sales in 2017 included a favorable one-time adjustment of  $640 million  due to a change in estimate based on the av', 'url': 'filings\\\\AAPL\\\\0000320193-18-000145.html'}, {'company': 'AAPL', 'filing': '10-Q', 'period': '2018-08-01', 'snippet': ')% \\xa0 12,910 \\xa0 13,865 \\xa0 (7 )% (1) Includes deferrals and amortization of related software upgrade rights and non-software services. (2) Includes revenue from Digital Content and Services, AppleCare¬Æ, Apple Pay, licensing and other services. Services net sales in the third quarter of 2018 included a favorable one-time item of $236 million in connection with the final resolution of various lawsuits. (3) Includes sales of AirPods, Apple TV, Apple Watch, Beats¬Æ products, HomePod, iPod touch and other', 'url': 'filings\\\\AAPL\\\\0000320193-18-000100.html'}]\n",
      "Confidence: 0.85 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# === Setup: Chat history buffer ===\n",
    "chat_history = []\n",
    "\n",
    "# === Core function: conversational_get_answer ===\n",
    "def conversational_get_answer(query, k=5, snippet_len=500):\n",
    "    hits = vector_store.similarity_search(query, k=k)\n",
    "    context = \"\\n\".join([hit.page_content[:snippet_len] for hit in hits])\n",
    "    sources = []\n",
    "    for hit in hits:\n",
    "        meta = hit.metadata.copy()\n",
    "        sources.append({\n",
    "            \"company\": meta.get(\"company\"),\n",
    "            \"filing\": meta.get(\"form\"),\n",
    "            \"period\": meta.get(\"date\") or meta.get(\"year\"),\n",
    "            \"snippet\": hit.page_content[:snippet_len],\n",
    "            \"url\": meta.get(\"url\", meta.get(\"source\"))\n",
    "        })\n",
    "\n",
    "    # Prepare chat history string for the prompt (up to last 5 exchanges)\n",
    "    chat_history_str = \"\"\n",
    "    for q, a in chat_history[-5:]:\n",
    "        chat_history_str += f\"User: {q}\\nSystem: {a}\\n\"\n",
    "\n",
    "    # Build prompt with chat history\n",
    "    prompt_text = f\"\"\"\n",
    "You are a financial analyst AI.\n",
    "\n",
    "Chat history:\n",
    "{chat_history_str}\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Step by step, answer the following question. If comparison or trend analysis is needed, break down the reasoning and show calculations. Cite each source as you use it.\n",
    "\n",
    "{query}\n",
    "\n",
    "Respond ONLY with a valid JSON of the form:\n",
    "{{\n",
    "    \"answer\": \"...your answer...\",\n",
    "    \"sources\": [{{\"company\": \"...\", \"filing\": \"...\", \"period\": \"...\", \"snippet\": \"...\", \"url\": \"...\"}}],\n",
    "    \"confidence\": 0.92\n",
    "}}\n",
    "\"\"\"\n",
    "\n",
    "    # Get LLM output (direct call, NOT LLMChain with memory)\n",
    "    result = model.invoke(prompt_text)\n",
    "    import json\n",
    "    try:\n",
    "        parsed = json.loads(result)\n",
    "        if \"answer\" not in parsed:\n",
    "            parsed = {\"answer\": result, \"sources\": sources, \"confidence\": 0.85}\n",
    "    except Exception:\n",
    "        parsed = {\"answer\": result, \"sources\": sources, \"confidence\": 0.85}\n",
    "\n",
    "    # Add this turn to history\n",
    "    chat_history.append((query, parsed['answer']))\n",
    "    return parsed\n",
    "\n",
    "# CLI Loop\n",
    "while True:\n",
    "    user_query = input(\"User: \")\n",
    "    if user_query.lower() in [\"exit\", \"quit\"]:\n",
    "        break\n",
    "    response = conversational_get_answer(user_query)\n",
    "    print(\"\\nSystem:\", response[\"answer\"])\n",
    "    print(\"Sources:\", response[\"sources\"])\n",
    "    print(\"Confidence:\", response.get(\"confidence\", \"N/A\"), \"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff97b99",
   "metadata": {},
   "source": [
    "## Conversational Financial Q&A Agent (Basic Version) with desired scehma 'StructuredOutputParser'\n",
    "\n",
    "This cell defines a function for a retrieval-augmented generation (RAG) pipeline using LangChain.\n",
    "It retrieves relevant SEC filings using a vectorstore, builds a prompt (with optional chat history), and queries a language model.\n",
    "The answer is returned as a JSON object with answer, sources, and confidence fields.  \n",
    "This version uses a generic prompt and does not maintain multi-turn chat history by default.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43aa6c08",
   "metadata": {},
   "source": [
    "## ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "346732a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: The excerpts provided do not explicitly state Apple's total revenue for Q1 2018. They include references to various revenue components and notes about changes in accounting standards and one-time items, but no direct figure for total revenue in Q1 2018.\n",
      "\n",
      "To answer your question precisely: **The provided excerpts do not contain Apple's total revenue for Q1 2018.**\n",
      "\n",
      "If you need the exact revenue figure, I recommend consulting Apple's official Q1 2018 Form 10-Q or earnings release, which would have the detailed financial statements including total revenue.\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import LLMChain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "# Define the model\n",
    "model = ChatOpenAI(model=\"gpt-4.1-mini\")  # Use the appropriate model\n",
    "# model = get_llm()\n",
    "\n",
    "# Define the prompt template to structure the query and context\n",
    "prompt_template = \"\"\"\n",
    "Here are some excerpts from financial documents related to your query:\n",
    "\n",
    "{context}\n",
    "\n",
    "Based on the above context, please answer the following question:\n",
    "{query}\n",
    "\"\"\"\n",
    "\n",
    "# Initialize LLMChain with the model and the prompt template\n",
    "prompt = PromptTemplate(input_variables=[\"query\", \"context\"], template=prompt_template)\n",
    "llm_chain = LLMChain(llm=model, prompt=prompt)\n",
    "\n",
    "# Function to generate an answer from the query and the retrieved context\n",
    "def get_answer(query):\n",
    "    # Perform similarity search to retrieve relevant document chunks\n",
    "    hits = vector_store.similarity_search(query, k=5)\n",
    "    \n",
    "    # Prepare the context by concatenating snippets from the top k documents\n",
    "    context = \"\\n\".join([hit.page_content[:500] for hit in hits])  # You can adjust the snippet length as needed\n",
    "    \n",
    "    # Get the answer from the model using LLMChain\n",
    "    answer = llm_chain.run({\"query\": query, \"context\": context})\n",
    "    return answer\n",
    "\n",
    "# Example quer?y\n",
    "query = \"What was Apple's revenue for Q1 2018?\"\n",
    "answer = get_answer(query)\n",
    "\n",
    "print(\"Answer:\", answer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d08bbdd2",
   "metadata": {},
   "source": [
    "## groq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4933d10d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üî∑ Using Groq (Llama-3-70B-8192) for LLM Q&A\n",
      "Answer: $61,137 million\n",
      "Sources: [{'company': 'Apple Inc.', 'filing': 'Q1 2018 Form 10-Q', 'period': 'Q1 2018', 'snippet': 'Net sales $ 61,137 $ 52,578', 'url': 'https://www.sec.gov/Archives/edgar/data/0000320193/000032019301000004/a10-q2018.htm'}]\n",
      "Confidence: 0.95\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.output_parsers import StructuredOutputParser, ResponseSchema\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "# 1. Define the desired output schema\n",
    "answer_schema = ResponseSchema(\n",
    "    name=\"answer\",\n",
    "    description=\"The answer to the user's financial question, grounded in context.\"\n",
    ")\n",
    "sources_schema = ResponseSchema(\n",
    "    name=\"sources\",\n",
    "    description=\"A list of source dictionaries with 'company', 'filing', 'period', 'snippet', and 'url' fields.\"\n",
    ")\n",
    "confidence_schema = ResponseSchema(\n",
    "    name=\"confidence\",\n",
    "    description=\"A float between 0 and 1 expressing the model's confidence in its answer.\"\n",
    ")\n",
    "\n",
    "# 2. Setup the parser\n",
    "output_parser = StructuredOutputParser.from_response_schemas(\n",
    "    [answer_schema, sources_schema, confidence_schema]\n",
    ")\n",
    "\n",
    "# 3. Create prompt template\n",
    "prompt_template = PromptTemplate(\n",
    "    input_variables=[\"chat_history\", \"context\", \"query\"],\n",
    "    template=\"\"\"\n",
    "You are a financial analyst AI assistant.\n",
    "\n",
    "Chat history:\n",
    "{chat_history}\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Answer the following question as thoroughly as possible, showing reasoning step by step if needed. \n",
    "Return your response as a JSON with fields: 'answer', 'sources', and 'confidence'.\n",
    "\n",
    "{format_instructions}\n",
    "\n",
    "User question: {query}\n",
    "\"\"\",\n",
    "    partial_variables={\"format_instructions\": output_parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "# 4. Create the model and function\n",
    "# model = ChatOpenAI(model=\"gpt-4.1-mini\")\n",
    "model = get_llm()\n",
    "\n",
    "def conversational_get_answer(query, k=5, snippet_len=500):\n",
    "    # Retrieve context (same as before)\n",
    "    hits = vector_store.similarity_search(query, k=k)\n",
    "    context = \"\\n\".join([hit.page_content[:snippet_len] for hit in hits])\n",
    "    sources = []\n",
    "    for hit in hits:\n",
    "        meta = hit.metadata.copy()\n",
    "        sources.append({\n",
    "            \"company\": meta.get(\"company\"),\n",
    "            \"filing\": meta.get(\"form\"),\n",
    "            \"period\": meta.get(\"date\") or meta.get(\"year\"),\n",
    "            \"snippet\": hit.page_content[:snippet_len],\n",
    "            \"url\": meta.get(\"url\", meta.get(\"source\"))\n",
    "        })\n",
    "\n",
    "    # Manual chat history management (see previous cell)\n",
    "    chat_history_str = \"\"  # Build this string from your turns as before\n",
    "\n",
    "    # Build prompt\n",
    "    prompt = prompt_template.format(\n",
    "        chat_history=chat_history_str,\n",
    "        context=context,\n",
    "        query=query,\n",
    "    )\n",
    "\n",
    "    # 5. Invoke the chain and parse JSON output robustly\n",
    "    raw_output = model.invoke(prompt)\n",
    "    if hasattr(raw_output, \"content\"):\n",
    "        raw_output = raw_output.content  # For ChatOpenAI and other chat models\n",
    "    parsed = output_parser.parse(raw_output)\n",
    "\n",
    "    if not parsed.get(\"sources\"):  # Fill sources if model leaves it blank\n",
    "        parsed[\"sources\"] = sources\n",
    "    return parsed\n",
    "\n",
    "# Example usage:\n",
    "query = \"What was Apple's revenue for Q1 2018?\"\n",
    "response = conversational_get_answer(query)\n",
    "print(\"Answer:\", response[\"answer\"])\n",
    "print(\"Sources:\", response[\"sources\"])\n",
    "print(\"Confidence:\", response[\"confidence\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca6af549",
   "metadata": {},
   "source": [
    "## ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fa261ff0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: The provided context does not explicitly state Apple's revenue for Q1 2018. However, the context references Apple's Q1 2018 Form 10-Q and mentions various financial metrics and discussions but does not give a direct revenue figure for that quarter. To find the exact revenue for Q1 2018, one would need to refer directly to Apple's Q1 2018 Form 10-Q filing or official earnings release for that period.\n",
      "Sources: [{'company': 'Apple Inc.', 'filing': 'Q1 2018 Form 10-Q', 'period': 'Q1 2018', 'snippet': 'The Company will adopt the new revenue standards in its first quarter of 2019 utilizing the full retrospective transition method. The new revenue standards are not expected to have a material impact on the amount and timing of revenue recognized in the Company‚Äôs consolidated financial statements.', 'url': 'https://www.sec.gov/Archives/edgar/data/320193/000032019318000070/a10q201831.htm'}]\n",
      "Confidence: 0.6\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.output_parsers import StructuredOutputParser, ResponseSchema\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "# 1. Define the desired output schema\n",
    "answer_schema = ResponseSchema(\n",
    "    name=\"answer\",\n",
    "    description=\"The answer to the user's financial question, grounded in context.\"\n",
    ")\n",
    "sources_schema = ResponseSchema(\n",
    "    name=\"sources\",\n",
    "    description=\"A list of source dictionaries with 'company', 'filing', 'period', 'snippet', and 'url' fields.\"\n",
    ")\n",
    "confidence_schema = ResponseSchema(\n",
    "    name=\"confidence\",\n",
    "    description=\"A float between 0 and 1 expressing the model's confidence in its answer.\"\n",
    ")\n",
    "\n",
    "# 2. Setup the parser\n",
    "output_parser = StructuredOutputParser.from_response_schemas(\n",
    "    [answer_schema, sources_schema, confidence_schema]\n",
    ")\n",
    "\n",
    "# 3. Create prompt template\n",
    "prompt_template = PromptTemplate(\n",
    "    input_variables=[\"chat_history\", \"context\", \"query\"],\n",
    "    template=\"\"\"\n",
    "You are a financial analyst AI assistant.\n",
    "\n",
    "Chat history:\n",
    "{chat_history}\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Answer the following question as thoroughly as possible, showing reasoning step by step if needed. \n",
    "Return your response as a JSON with fields: 'answer', 'sources', and 'confidence'.\n",
    "\n",
    "{format_instructions}\n",
    "\n",
    "User question: {query}\n",
    "\"\"\",\n",
    "    partial_variables={\"format_instructions\": output_parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "# 4. Create the model and function\n",
    "model = ChatOpenAI(model=\"gpt-4.1-mini\")\n",
    "# model = get_llm()\n",
    "\n",
    "def conversational_get_answer(query, k=5, snippet_len=500):\n",
    "    # Retrieve context (same as before)\n",
    "    hits = vector_store.similarity_search(query, k=k)\n",
    "    context = \"\\n\".join([hit.page_content[:snippet_len] for hit in hits])\n",
    "    sources = []\n",
    "    for hit in hits:\n",
    "        meta = hit.metadata.copy()\n",
    "        sources.append({\n",
    "            \"company\": meta.get(\"company\"),\n",
    "            \"filing\": meta.get(\"form\"),\n",
    "            \"period\": meta.get(\"date\") or meta.get(\"year\"),\n",
    "            \"snippet\": hit.page_content[:snippet_len],\n",
    "            \"url\": meta.get(\"url\", meta.get(\"source\"))\n",
    "        })\n",
    "\n",
    "    # Manual chat history management (see previous cell)\n",
    "    chat_history_str = \"\"  # Build this string from your turns as before\n",
    "\n",
    "    # Build prompt\n",
    "    prompt = prompt_template.format(\n",
    "        chat_history=chat_history_str,\n",
    "        context=context,\n",
    "        query=query,\n",
    "    )\n",
    "\n",
    "    # 5. Invoke the chain and parse JSON output robustly\n",
    "    raw_output = model.invoke(prompt)\n",
    "    if hasattr(raw_output, \"content\"):\n",
    "        raw_output = raw_output.content  # For ChatOpenAI and other chat models\n",
    "    parsed = output_parser.parse(raw_output)\n",
    "\n",
    "    if not parsed.get(\"sources\"):  # Fill sources if model leaves it blank\n",
    "        parsed[\"sources\"] = sources\n",
    "    return parsed\n",
    "\n",
    "# Example usage:\n",
    "query = \"What was Apple's revenue for Q1 2018?\"\n",
    "response = conversational_get_answer(query)\n",
    "print(\"Answer:\", response[\"answer\"])\n",
    "print(\"Sources:\", response[\"sources\"])\n",
    "print(\"Confidence:\", response[\"confidence\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "478c3842",
   "metadata": {},
   "source": [
    "## Conversational Financial Q&A Agent (Robust, MAG7-specific, Multi-turn)\n",
    "\n",
    "This cell defines an advanced RAG pipeline for MAG7 financial Q&A using LangChain. with desired scehma 'StructuredOutputParser'\n",
    "It uses a robust prompt with explicit instructions, tracks recent chat history for multi-turn conversations, and includes error handling.\n",
    "Answers are always returned as structured JSON with answer, sources, and confidence fields.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be691a31",
   "metadata": {},
   "source": [
    "## Groq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a2c5678",
   "metadata": {},
   "source": [
    "## ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fec47560",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üî∑ MAG7 Conversational Agent (multi-turn, typo-tolerant, step-by-step). Type 'exit' to quit.\n",
      "\n",
      "\n",
      "User: \n",
      "\n",
      "System: Searching relevant sections from 10-K/Q filings...\n",
      "\n",
      "Response:\n",
      "{\n",
      "  \"answer\": \"There is no user question provided to answer. Please provide a specific question regarding the Magnificent 7 companies (AAPL, MSFT, AMZN, GOOGL, META, NVDA, TSLA) for me to assist you.\",\n",
      "  \"sources\": [\n",
      "    {\n",
      "      \"company\": \"TSLA\",\n",
      "      \"filing\": \"10-Q\",\n",
      "      \"period\": \"2017-08-04\",\n",
      "      \"snippet\": \"20\",\n",
      "      \"url\": \"filings\\\\TSLA\\\\0001564590-17-015705.html\"\n",
      "    },\n",
      "    {\n",
      "      \"company\": \"TSLA\",\n",
      "      \"filing\": \"10-Q\",\n",
      "      \"period\": \"2018-08-06\",\n",
      "      \"snippet\": \"17\",\n",
      "      \"url\": \"filings\\\\TSLA\\\\0001564590-18-019254.html\"\n",
      "    },\n",
      "    {\n",
      "      \"company\": \"TSLA\",\n",
      "      \"filing\": \"10-Q\",\n",
      "      \"period\": \"2018-11-02\",\n",
      "      \"snippet\": \"18\",\n",
      "      \"url\": \"filings\\\\TSLA\\\\0001564590-18-026353.html\"\n",
      "    },\n",
      "    {\n",
      "      \"company\": \"TSLA\",\n",
      "      \"filing\": \"10-Q\",\n",
      "      \"period\": \"2017-05-10\",\n",
      "      \"snippet\": \"31\",\n",
      "      \"url\": \"filings\\\\TSLA\\\\0001564590-17-009968.html\"\n",
      "    },\n",
      "    {\n",
      "      \"company\": \"TSLA\",\n",
      "      \"filing\": \"10-Q\",\n",
      "      \"period\": \"2017-11-03\",\n",
      "      \"snippet\": \"31\",\n",
      "      \"url\": \"filings\\\\TSLA\\\\0001564590-17-021343.html\"\n",
      "    }\n",
      "  ],\n",
      "  \"confidence\": \"1\"\n",
      "}\n",
      "\n",
      "---\n",
      "\n",
      "\n",
      "User: helllo\n",
      "\n",
      "System: Searching relevant sections from 10-K/Q filings...\n",
      "\n",
      "Response:\n",
      "{\n",
      "  \"answer\": \"It seems your message was 'helllo', which looks like a greeting or a typo for 'hello'. Please provide a specific question related to the Magnificent 7 companies (AAPL, MSFT, AMZN, GOOGL, META, NVDA, TSLA) so I can assist you.\",\n",
      "  \"sources\": [\n",
      "    {\n",
      "      \"company\": \"TSLA\",\n",
      "      \"filing\": \"10-Q\",\n",
      "      \"period\": \"2017-05-10\",\n",
      "      \"snippet\": \"41\",\n",
      "      \"url\": \"filings\\\\TSLA\\\\0001564590-17-009968.html\"\n",
      "    },\n",
      "    {\n",
      "      \"company\": \"TSLA\",\n",
      "      \"filing\": \"10-Q\",\n",
      "      \"period\": \"2017-08-04\",\n",
      "      \"snippet\": \"20\",\n",
      "      \"url\": \"filings\\\\TSLA\\\\0001564590-17-015705.html\"\n",
      "    },\n",
      "    {\n",
      "      \"company\": \"TSLA\",\n",
      "      \"filing\": \"10-Q\",\n",
      "      \"period\": \"2018-08-06\",\n",
      "      \"snippet\": \"17\",\n",
      "      \"url\": \"filings\\\\TSLA\\\\0001564590-18-019254.html\"\n",
      "    },\n",
      "    {\n",
      "      \"company\": \"TSLA\",\n",
      "      \"filing\": \"10-Q\",\n",
      "      \"period\": \"2017-05-10\",\n",
      "      \"snippet\": \"31\",\n",
      "      \"url\": \"filings\\\\TSLA\\\\0001564590-17-009968.html\"\n",
      "    },\n",
      "    {\n",
      "      \"company\": \"TSLA\",\n",
      "      \"filing\": \"10-Q\",\n",
      "      \"period\": \"2017-11-03\",\n",
      "      \"snippet\": \"31\",\n",
      "      \"url\": \"filings\\\\TSLA\\\\0001564590-17-021343.html\"\n",
      "    }\n",
      "  ],\n",
      "  \"confidence\": \"1.0\"\n",
      "}\n",
      "\n",
      "---\n",
      "\n",
      "\n",
      "User: what is the Apple's revenue in Q1 2018?\n",
      "\n",
      "System: Searching relevant sections from 10-K/Q filings...\n",
      "\n",
      "Response:\n",
      "{\n",
      "  \"answer\": \"The provided context does not explicitly state Apple's total revenue for Q1 2018. It includes references to sales and expenses in other periods of 2018, but the exact revenue figure for Q1 2018 is not present.\",\n",
      "  \"sources\": [\n",
      "    {\n",
      "      \"company\": \"AAPL\",\n",
      "      \"filing\": \"10-Q\",\n",
      "      \"period\": \"2018-05-02\",\n",
      "      \"snippet\": \"to its future growth and competitive position in the marketplace, and to the development of new and updated products and services that are central to the Company‚Äôs core business strategy. Selling, General and Administrative The growth in selling, general and administrative expense during the second quarter and first six months of 2018 compared to the same periods in 2017 was driven primarily by increases in headcount-related expenses and infrastructure-related costs. Apple Inc. | Q2 2018 Form 10\",\n",
      "      \"url\": \"filings\\\\AAPL\\\\0000320193-18-000070.html\"\n",
      "    },\n",
      "    {\n",
      "      \"company\": \"AAPL\",\n",
      "      \"filing\": \"10-Q\",\n",
      "      \"period\": \"2018-08-01\",\n",
      "      \"snippet\": \")% ¬† 12,910 ¬† 13,865 ¬† (7 )% (1) Includes deferrals and amortization of related software upgrade rights and non-software services. (2) Includes revenue from Digital Content and Services, AppleCare¬Æ, Apple Pay, licensing and other services. Services net sales in the third quarter of 2018 included a favorable one-time item of $236 million in connection with the final resolution of various lawsuits. (3) Includes sales of AirPods, Apple TV, Apple Watch, Beats¬Æ products, HomePod, iPod touch and other\",\n",
      "      \"url\": \"filings\\\\AAPL\\\\0000320193-18-000100.html\"\n",
      "    },\n",
      "    {\n",
      "      \"company\": \"AAPL\",\n",
      "      \"filing\": \"10-K\",\n",
      "      \"period\": \"2018-11-05\",\n",
      "      \"snippet\": \"229,234 $ 215,639 ¬† (1) Includes deferrals and amortization of related software upgrade rights and non-software services. (2) Includes revenue from Digital Content and Services, AppleCare, Apple Pay, licensing and other services. Services net sales in 2018 included a favorable one-time item of  $236 million  in connection with the final resolution of various lawsuits. Services net sales in 2017 included a favorable one-time adjustment of  $640 million  due to a change in estimate based on the av\",\n",
      "      \"url\": \"filings\\\\AAPL\\\\0000320193-18-000145.html\"\n",
      "    },\n",
      "    {\n",
      "      \"company\": \"AAPL\",\n",
      "      \"filing\": \"10-Q\",\n",
      "      \"period\": \"2018-02-02\",\n",
      "      \"snippet\": \"period presented or retrospectively with the cumulative effect recognized as of the date of adoption. The Company will adopt the new revenue standards in its first quarter of 2019 utilizing the full retrospective transition method. The new revenue standards are not expected to have a material impact on the amount and timing of revenue recognized in the Company‚Äôs consolidated financial statements. Apple Inc. | Q1 2018 Form 10-Q |  28 Liquidity and Capital Resources The following tables present se\",\n",
      "      \"url\": \"filings\\\\AAPL\\\\0000320193-18-000007.html\"\n",
      "    },\n",
      "    {\n",
      "      \"company\": \"AAPL\",\n",
      "      \"filing\": \"10-Q\",\n",
      "      \"period\": \"2018-08-01\",\n",
      "      \"snippet\": \"and paid dividends and dividend equivalents of  $3.7 billion  during the  third  quarter of  2018 . Apple Inc. | Q3 2018 Form 10-Q |  23 Sales Data The following table shows net sales by reportable segment and net sales and unit sales by product for  the three- and nine-month periods ended June 30, 2018  and  July¬†1, 2017  (dollars in millions and units in thousands): ¬† Three Months Ended ¬† Nine Months Ended ¬† June¬†30,  2018 ¬† July¬†1,  2017 ¬† Change ¬† June¬†30,  2018 ¬† July¬†1,  2017 ¬† Change Net \",\n",
      "      \"url\": \"filings\\\\AAPL\\\\0000320193-18-000100.html\"\n",
      "    }\n",
      "  ],\n",
      "  \"confidence\": \"0.0\"\n",
      "}\n",
      "\n",
      "---\n",
      "\n",
      "\n",
      "User: what is the Apple's revenue in Q1 2018?\n",
      "\n",
      "System: Searching relevant sections from 10-K/Q filings...\n",
      "\n",
      "Response:\n",
      "{\n",
      "  \"answer\": \"The provided context does not explicitly state Apple's total revenue for Q1 2018. While there are references to sales and expenses in 2018, no specific figure for Apple's revenue in Q1 2018 is available in the provided excerpts.\",\n",
      "  \"sources\": [\n",
      "    {\n",
      "      \"company\": \"Apple\",\n",
      "      \"filing\": \"Q1 2018 Form 10-Q\",\n",
      "      \"period\": \"Q1 2018\",\n",
      "      \"snippet\": \"The new revenue standards are not expected to have a material impact on the amount and timing of revenue recognized in the Company‚Äôs consolidated financial statements.\",\n",
      "      \"url\": \"\"\n",
      "    }\n",
      "  ],\n",
      "  \"confidence\": \"0.8\"\n",
      "}\n",
      "\n",
      "---\n",
      "\n",
      "\n",
      "User: what is the Apple's revenue in Q1 2018?\n",
      "\n",
      "System: Searching relevant sections from 10-K/Q filings...\n",
      "\n",
      "Response:\n",
      "{\n",
      "  \"answer\": \"The provided context does not explicitly state Apple's total revenue for Q1 2018. While there are references to sales, expenses, and other financial data in 2018, the exact revenue figure for Apple's Q1 2018 is not present in the excerpts provided.\",\n",
      "  \"sources\": [\n",
      "    {\n",
      "      \"company\": \"Apple Inc.\",\n",
      "      \"filing\": \"Q1 2018 Form 10-Q\",\n",
      "      \"period\": \"Q1 2018\",\n",
      "      \"snippet\": \"The new revenue standards are not expected to have a material impact on the amount and timing of revenue recognized in the Company‚Äôs consolidated financial statements.\",\n",
      "      \"url\": \"\"\n",
      "    },\n",
      "    {\n",
      "      \"company\": \"Apple Inc.\",\n",
      "      \"filing\": \"Q2 2018 Form 10\",\n",
      "      \"period\": \"Q2 2018\",\n",
      "      \"snippet\": \"Selling, General and Administrative expense during the second quarter and first six months of 2018 compared to the same periods in 2017 was driven primarily by increases in headcount-related expenses and infrastructure-related costs.\",\n",
      "      \"url\": \"\"\n",
      "    }\n",
      "  ],\n",
      "  \"confidence\": \"0.9\"\n",
      "}\n",
      "\n",
      "---\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.output_parsers import StructuredOutputParser, ResponseSchema\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "# 1. Output schema for structured JSON\n",
    "answer_schema = ResponseSchema(\n",
    "    name=\"answer\",\n",
    "    description=\"The final answer to the user's question, with step-by-step reasoning if needed.\"\n",
    ")\n",
    "sources_schema = ResponseSchema(\n",
    "    name=\"sources\",\n",
    "    description=\"A list of dicts with keys: company, filing, period, snippet, url, showing where info came from.\"\n",
    ")\n",
    "confidence_schema = ResponseSchema(\n",
    "    name=\"confidence\",\n",
    "    description=\"A float between 0 and 1 expressing confidence in the answer.\"\n",
    ")\n",
    "output_parser = StructuredOutputParser.from_response_schemas(\n",
    "    [answer_schema, sources_schema, confidence_schema]\n",
    ")\n",
    "\n",
    "# 2. Prompt template (with all instructions)\n",
    "prompt_template = PromptTemplate(\n",
    "    input_variables=[\"chat_history\", \"context\", \"query\"],\n",
    "    template=\"\"\"\n",
    "You are a financial Q&A AI agent for the Magnificent 7 (AAPL, MSFT, AMZN, GOOGL, META, NVDA, TSLA).\n",
    "Your instructions:\n",
    "- Accept and answer all user queries, including complex, comparative, or trend questions.\n",
    "- Auto-correct obvious typos (e.g., 'Q1 20218' ‚Üí 'Q1 2018'). If unsure, clarify.\n",
    "- Use the chat history to interpret follow-ups.\n",
    "- Only answer using the provided context (from SEC filings); never guess or hallucinate data.\n",
    "- For comparative, trend, or multi-step queries, reason step by step in the 'answer' field.\n",
    "- Always cite your sources in a list of dicts with company, filing, period, snippet, and url.\n",
    "- If context is missing, state so clearly.\n",
    "- Output ONLY valid JSON with these fields: answer, sources, confidence.\n",
    "\n",
    "{format_instructions}\n",
    "\n",
    "Chat history:\n",
    "{chat_history}\n",
    "\n",
    "Context from SEC filings:\n",
    "{context}\n",
    "\n",
    "User question: {query}\n",
    "\"\"\",\n",
    "    partial_variables={\"format_instructions\": output_parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "# 3. LLM setup (OpenAI, or your chosen model)\n",
    "model = ChatOpenAI(model=\"gpt-4.1-mini\")  # Or your OpenAI API/model of choice\n",
    "\n",
    "# 4. Conversation memory\n",
    "chat_history = []\n",
    "\n",
    "def conversational_get_answer(query, k=5, snippet_len=500):\n",
    "    # Vector search to get relevant context\n",
    "    hits = vector_store.similarity_search(query, k=k)\n",
    "    context = \"\\n\".join([hit.page_content[:snippet_len] for hit in hits])\n",
    "    sources = []\n",
    "    for hit in hits:\n",
    "        meta = hit.metadata.copy()\n",
    "        sources.append({\n",
    "            \"company\": meta.get(\"company\"),\n",
    "            \"filing\": meta.get(\"form\"),\n",
    "            \"period\": meta.get(\"date\") or meta.get(\"year\"),\n",
    "            \"snippet\": hit.page_content[:snippet_len],\n",
    "            \"url\": meta.get(\"url\", meta.get(\"source\"))\n",
    "        })\n",
    "\n",
    "    # Format chat history for prompt\n",
    "    chat_history_str = \"\"\n",
    "    for q, a in chat_history[-6:]:\n",
    "        chat_history_str += f\"User: {q}\\nAgent: {a}\\n\"\n",
    "\n",
    "    # Compose the prompt\n",
    "    prompt = prompt_template.format(\n",
    "        chat_history=chat_history_str,\n",
    "        context=context,\n",
    "        query=query,\n",
    "    )\n",
    "\n",
    "    # LLM call and output parsing\n",
    "    raw_output = model.invoke(prompt)\n",
    "    if hasattr(raw_output, \"content\"):\n",
    "        raw_output = raw_output.content\n",
    "\n",
    "    # Try parsing as structured JSON\n",
    "    try:\n",
    "        parsed = output_parser.parse(raw_output)\n",
    "        if not parsed.get(\"sources\"):\n",
    "            parsed[\"sources\"] = sources\n",
    "    except Exception:\n",
    "        parsed = {\"answer\": raw_output, \"sources\": sources, \"confidence\": 0.7}\n",
    "\n",
    "    # Save to chat history for follow-ups\n",
    "    chat_history.append((query, parsed[\"answer\"]))\n",
    "    return parsed\n",
    "\n",
    "# 5. CLI loop (MATCHES THE IMAGE)\n",
    "print(\"üî∑ MAG7 Conversational Agent (multi-turn, typo-tolerant, step-by-step). Type 'exit' to quit.\\n\")\n",
    "while True:\n",
    "    user_query = input(\"User: \")\n",
    "    if user_query.strip().lower() in [\"exit\", \"quit\"]:\n",
    "        break\n",
    "    print(f\"\\nUser: {user_query}\\n\")\n",
    "    print(\"System: Searching relevant sections from 10-K/Q filings...\\n\")\n",
    "    response = conversational_get_answer(user_query)\n",
    "    print(\"Response:\")\n",
    "    print(json.dumps(response, indent=2, ensure_ascii=False))\n",
    "    print(\"\\n---\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a892c0a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag7",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
